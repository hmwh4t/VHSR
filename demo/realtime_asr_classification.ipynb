{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf33fcff",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ba807d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install dependencies\n",
    "# !pip install torch transformers pyaudio numpy chunkformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813156b",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9d21d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import wave\n",
    "import tempfile\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from chunkformer import ChunkFormerModel\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d38b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration for the real-time ASR + Classification system.\"\"\"\n",
    "    # Model paths\n",
    "    ASR_MODEL_PATH: str = \"khanhld/chunkformer-ctc-large-vie\"\n",
    "    CLASSIFIER_MODEL_PATH: str = \"model/checkpoint-25000\"\n",
    "    \n",
    "    # Audio settings\n",
    "    SAMPLE_RATE: int = 16000\n",
    "    CHANNELS: int = 1\n",
    "    CHUNK_SIZE: int = 1024\n",
    "    INPUT_DEVICE_INDEX: Optional[int] = None  # None uses default device\n",
    "    \n",
    "    # Recording settings\n",
    "    MAX_RECORDING_DURATION: float = 30.0  # Max seconds before forced transcription\n",
    "    SILENCE_DURATION: float = 2.0  # Seconds of silence to trigger transcription\n",
    "    \n",
    "    # Noise calibration settings (more robust)\n",
    "    NOISE_CALIBRATION_DURATION: float = 3.0  # Seconds to record for calibration\n",
    "    NOISE_PERCENTILE: float = 95.0  # Use 95th percentile for robust estimation\n",
    "    NOISE_MULTIPLIER: float = 2.5  # Multiplier above noise floor\n",
    "    MIN_SILENCE_THRESHOLD: float = 0.005  # Minimum threshold\n",
    "    MAX_SILENCE_THRESHOLD: float = 0.1  # Maximum threshold to prevent issues\n",
    "    CALIBRATION_SEGMENTS: int = 5  # Number of segments for robust estimation\n",
    "\n",
    "config = Config()\n",
    "print(\"Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a853e05f",
   "metadata": {},
   "source": [
    "## 3. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "368c4ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading ASR model: khanhld/chunkformer-ctc-large-vie...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ee8ce6b0b24e55b642546c4f5c4c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASR model loaded.\n",
      "Loading classifier model: model/checkpoint-25000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from 'model/checkpoint-25000' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier model loaded.\n",
      "\n",
      "✅ All models loaded successfully on cuda\n"
     ]
    }
   ],
   "source": [
    "# Determine device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load ASR model (ChunkFormer)\n",
    "print(f\"Loading ASR model: {config.ASR_MODEL_PATH}...\")\n",
    "asr_model = ChunkFormerModel.from_pretrained(config.ASR_MODEL_PATH)\n",
    "if device.type == \"cuda\":\n",
    "    asr_model = asr_model.cuda()\n",
    "print(\"ASR model loaded.\")\n",
    "\n",
    "# Load Classification model (mDeBERTa)\n",
    "print(f\"Loading classifier model: {config.CLASSIFIER_MODEL_PATH}...\")\n",
    "classifier_tokenizer = AutoTokenizer.from_pretrained(config.CLASSIFIER_MODEL_PATH)\n",
    "classifier_model = AutoModelForSequenceClassification.from_pretrained(config.CLASSIFIER_MODEL_PATH)\n",
    "classifier_model = classifier_model.to(device)\n",
    "classifier_model.eval()\n",
    "print(\"Classifier model loaded.\")\n",
    "\n",
    "print(f\"\\n✅ All models loaded successfully on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793c8b7",
   "metadata": {},
   "source": [
    "## 4. Robust Noise Calibration System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4c51a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustNoiseCalibrator:\n",
    "    \"\"\"\n",
    "    Robust noise calibration using multiple statistical methods:\n",
    "    - Percentile-based estimation (resistant to outliers)\n",
    "    - Segmented analysis for consistency\n",
    "    - Adaptive thresholding with bounds\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.silence_threshold = config.MIN_SILENCE_THRESHOLD\n",
    "        self.noise_stats = {}\n",
    "        \n",
    "    def list_audio_devices(self) -> List[Dict]:\n",
    "        \"\"\"List available audio input devices.\"\"\"\n",
    "        p = pyaudio.PyAudio()\n",
    "        devices = []\n",
    "        try:\n",
    "            info = p.get_host_api_info_by_index(0)\n",
    "            num_devices = info.get('deviceCount', 0)\n",
    "            \n",
    "            print(\"Available Audio Input Devices:\")\n",
    "            for i in range(num_devices):\n",
    "                dev_info = p.get_device_info_by_host_api_device_index(0, i)\n",
    "                if dev_info.get('maxInputChannels', 0) > 0:\n",
    "                    name = dev_info.get('name', 'Unknown')\n",
    "                    devices.append({'index': i, 'name': name})\n",
    "                    print(f\"  [{i}] {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error listing devices: {e}\")\n",
    "        finally:\n",
    "            p.terminate()\n",
    "        return devices\n",
    "    \n",
    "    def _compute_rms(self, audio: np.ndarray) -> float:\n",
    "        \"\"\"Compute RMS of audio signal.\"\"\"\n",
    "        return float(np.sqrt(np.mean(audio ** 2)))\n",
    "    \n",
    "    def _compute_percentile_amplitude(self, audio: np.ndarray, percentile: float) -> float:\n",
    "        \"\"\"Compute percentile of absolute amplitude.\"\"\"\n",
    "        return float(np.percentile(np.abs(audio), percentile))\n",
    "    \n",
    "    def calibrate(self, show_progress: bool = True) -> Dict:\n",
    "        \"\"\"\n",
    "        Perform robust noise calibration.\n",
    "        \n",
    "        Returns:\n",
    "            Dict with calibration statistics and computed threshold\n",
    "        \"\"\"\n",
    "        duration = self.config.NOISE_CALIBRATION_DURATION\n",
    "        num_segments = self.config.CALIBRATION_SEGMENTS\n",
    "        \n",
    "        if show_progress:\n",
    "            print(f\"Noise Calibration - Stay silent for {duration:.1f}s...\")\n",
    "        \n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=self.config.CHANNELS,\n",
    "            rate=self.config.SAMPLE_RATE,\n",
    "            input=True,\n",
    "            input_device_index=self.config.INPUT_DEVICE_INDEX,\n",
    "            frames_per_buffer=self.config.CHUNK_SIZE\n",
    "        )\n",
    "        \n",
    "        # Collect audio in segments for robust analysis\n",
    "        segment_duration = duration / num_segments\n",
    "        chunks_per_segment = int(self.config.SAMPLE_RATE * segment_duration / self.config.CHUNK_SIZE)\n",
    "        \n",
    "        all_audio = []\n",
    "        segment_rms_values = []\n",
    "        segment_percentiles = []\n",
    "        \n",
    "        for seg in range(num_segments):\n",
    "            segment_frames = []\n",
    "            for _ in range(chunks_per_segment):\n",
    "                data = stream.read(self.config.CHUNK_SIZE, exception_on_overflow=False)\n",
    "                chunk = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "                segment_frames.append(chunk)\n",
    "            \n",
    "            segment_audio = np.concatenate(segment_frames)\n",
    "            all_audio.append(segment_audio)\n",
    "            \n",
    "            # Compute segment statistics\n",
    "            seg_rms = self._compute_rms(segment_audio)\n",
    "            seg_percentile = self._compute_percentile_amplitude(segment_audio, self.config.NOISE_PERCENTILE)\n",
    "            segment_rms_values.append(seg_rms)\n",
    "            segment_percentiles.append(seg_percentile)\n",
    "            \n",
    "            if show_progress:\n",
    "                progress = int((seg + 1) / num_segments * 100)\n",
    "                print(f\"\\r  Progress: {progress}%\", end=\"\")\n",
    "        \n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "        \n",
    "        if show_progress:\n",
    "            print()\n",
    "        \n",
    "        # Combine all audio for overall statistics\n",
    "        full_audio = np.concatenate(all_audio)\n",
    "        \n",
    "        # Compute robust statistics\n",
    "        overall_rms = self._compute_rms(full_audio)\n",
    "        overall_percentile = self._compute_percentile_amplitude(full_audio, self.config.NOISE_PERCENTILE)\n",
    "        \n",
    "        # Use median of segment values for robustness against transient noises\n",
    "        median_rms = float(np.median(segment_rms_values))\n",
    "        median_percentile = float(np.median(segment_percentiles))\n",
    "        \n",
    "        # Check for anomalies (segments with very different values)\n",
    "        rms_std = float(np.std(segment_rms_values))\n",
    "        is_stable = rms_std < median_rms * 0.5  # Less than 50% variation\n",
    "        \n",
    "        # Compute threshold using the more robust metric\n",
    "        base_noise = max(median_percentile, median_rms)\n",
    "        computed_threshold = base_noise * self.config.NOISE_MULTIPLIER\n",
    "        \n",
    "        # Clamp to valid range\n",
    "        final_threshold = np.clip(\n",
    "            computed_threshold,\n",
    "            self.config.MIN_SILENCE_THRESHOLD,\n",
    "            self.config.MAX_SILENCE_THRESHOLD\n",
    "        )\n",
    "        \n",
    "        self.silence_threshold = float(final_threshold)\n",
    "        \n",
    "        # Store statistics\n",
    "        self.noise_stats = {\n",
    "            'overall_rms': overall_rms,\n",
    "            'overall_percentile': overall_percentile,\n",
    "            'median_rms': median_rms,\n",
    "            'median_percentile': median_percentile,\n",
    "            'rms_std': rms_std,\n",
    "            'is_stable': is_stable,\n",
    "            'computed_threshold': computed_threshold,\n",
    "            'final_threshold': final_threshold,\n",
    "            'segment_rms_values': segment_rms_values\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        if show_progress:\n",
    "            status = \"OK\" if is_stable else \"Unstable\"\n",
    "            print(f\"Calibration complete [{status}]\")\n",
    "            print(f\"  Noise RMS: {median_rms:.5f}, Threshold: {final_threshold:.5f}\")\n",
    "            \n",
    "            if overall_rms < 0.0001:\n",
    "                print(\"  Warning: Very low noise - check if mic is muted\")\n",
    "        \n",
    "        return self.noise_stats\n",
    "    \n",
    "    def get_threshold(self) -> float:\n",
    "        \"\"\"Get the current silence threshold.\"\"\"\n",
    "        return self.silence_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4823e",
   "metadata": {},
   "source": [
    "## 5. Text Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63682570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Classify text using the mDeBERTa hate speech classifier.\n",
    "    \n",
    "    Args:\n",
    "        text: Vietnamese text to classify\n",
    "        \n",
    "    Returns:\n",
    "        Dict with label, confidence, and probabilities\n",
    "    \"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"predicted_label\": \"unknown\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"probabilities\": {}\n",
    "        }\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = classifier_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=True\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier_model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Get prediction\n",
    "    predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "    confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    # Map labels\n",
    "    id2label = classifier_model.config.id2label\n",
    "    def get_label(idx):\n",
    "        return id2label.get(idx, id2label.get(str(idx), f\"label_{idx}\"))\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"predicted_label\": get_label(predicted_class),\n",
    "        \"confidence\": confidence,\n",
    "        \"probabilities\": {\n",
    "            get_label(i): prob.item()\n",
    "            for i, prob in enumerate(probabilities[0])\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51936ed4",
   "metadata": {},
   "source": [
    "## 6. Real-time ASR + Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b258d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealtimeASRClassifierWidget:\n",
    "    \"\"\"\n",
    "    Real-time Vietnamese Speech Recognition with Hate Speech Classification.\n",
    "    Uses ipywidgets to display interactive controls and results.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config, calibrator: RobustNoiseCalibrator):\n",
    "        self.config = config\n",
    "        self.calibrator = calibrator\n",
    "        \n",
    "        # State\n",
    "        self.audio_buffer = np.array([], dtype=np.float32)\n",
    "        self.recording = False\n",
    "        self.paused = False\n",
    "        self.speech_active = False\n",
    "        self.last_speech_time = time.time()\n",
    "        self.lock = threading.Lock()\n",
    "        self._start_time = None\n",
    "        \n",
    "        # Results storage\n",
    "        self.results: List[Dict] = []\n",
    "        self._results_html = \"\"\n",
    "        \n",
    "        # Build UI widgets\n",
    "        self._build_ui()\n",
    "        \n",
    "    def _build_ui(self):\n",
    "        \"\"\"Build the widget UI.\"\"\"\n",
    "        # Status indicator\n",
    "        self.status_label = widgets.HTML(\n",
    "            value=\"<b style='color: gray;'>Ready</b>\",\n",
    "            layout=widgets.Layout(margin='5px 0')\n",
    "        )\n",
    "        \n",
    "        # Timer display\n",
    "        self.timer_label = widgets.HTML(\n",
    "            value=\"<b>Time: 00:00</b>\",\n",
    "            layout=widgets.Layout(margin='5px 0')\n",
    "        )\n",
    "        \n",
    "        # Recording indicator\n",
    "        self.recording_indicator = widgets.HTML(\n",
    "            value=\"\",\n",
    "            layout=widgets.Layout(margin='5px 0')\n",
    "        )\n",
    "        \n",
    "        # Results counter\n",
    "        self.results_counter = widgets.HTML(\n",
    "            value=\"<b>Results: 0</b>\",\n",
    "            layout=widgets.Layout(margin='5px 0')\n",
    "        )\n",
    "        \n",
    "        # Control buttons\n",
    "        self.pause_button = widgets.Button(\n",
    "            description='Pause',\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='100px'),\n",
    "            disabled=True\n",
    "        )\n",
    "        self.pause_button.on_click(self._on_pause_click)\n",
    "        \n",
    "        self.stop_button = widgets.Button(\n",
    "            description='Stop',\n",
    "            button_style='danger',\n",
    "            layout=widgets.Layout(width='100px'),\n",
    "            disabled=True\n",
    "        )\n",
    "        self.stop_button.on_click(self._on_stop_click)\n",
    "        \n",
    "        self.start_button = widgets.Button(\n",
    "            description='Start',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(width='100px')\n",
    "        )\n",
    "        self.start_button.on_click(self._on_start_click)\n",
    "        \n",
    "        self.clear_button = widgets.Button(\n",
    "            description='Clear',\n",
    "            button_style='',\n",
    "            layout=widgets.Layout(width='100px')\n",
    "        )\n",
    "        self.clear_button.on_click(self._on_clear_click)\n",
    "        \n",
    "        # Results display area - use HTML widget instead of Output for thread safety\n",
    "        self.results_html = widgets.HTML(\n",
    "            value=\"\",\n",
    "            layout=widgets.Layout(\n",
    "                height='400px',\n",
    "                overflow_y='auto',\n",
    "                border='1px solid #ccc',\n",
    "                padding='10px',\n",
    "                margin='10px 0'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Header section\n",
    "        header = widgets.HBox([\n",
    "            self.status_label,\n",
    "            widgets.HTML(value=\" | \"),\n",
    "            self.timer_label,\n",
    "            widgets.HTML(value=\" | \"),\n",
    "            self.results_counter,\n",
    "            widgets.HTML(value=\" \"),\n",
    "            self.recording_indicator\n",
    "        ])\n",
    "        \n",
    "        # Button row\n",
    "        button_row = widgets.HBox([\n",
    "            self.start_button,\n",
    "            self.pause_button,\n",
    "            self.stop_button,\n",
    "            self.clear_button\n",
    "        ], layout=widgets.Layout(margin='10px 0'))\n",
    "        \n",
    "        # Main container\n",
    "        self.main_widget = widgets.VBox([\n",
    "            widgets.HTML(value=\"<h3>Real-time ASR + Classification</h3>\"),\n",
    "            header,\n",
    "            button_row,\n",
    "            widgets.HTML(value=\"<b>Results:</b>\"),\n",
    "            self.results_html\n",
    "        ], layout=widgets.Layout(padding='10px', border='2px solid #333', border_radius='10px'))\n",
    "    \n",
    "    def _on_start_click(self, b):\n",
    "        self.start()\n",
    "    \n",
    "    def _on_pause_click(self, b):\n",
    "        if self.paused:\n",
    "            self.resume()\n",
    "        else:\n",
    "            self.pause()\n",
    "    \n",
    "    def _on_stop_click(self, b):\n",
    "        self.stop()\n",
    "    \n",
    "    def _on_clear_click(self, b):\n",
    "        self.results = []\n",
    "        self._results_html = \"\"\n",
    "        self.results_html.value = \"\"\n",
    "        self._update_results_counter()\n",
    "        \n",
    "    def _update_status(self, status: str, color: str = \"gray\"):\n",
    "        self.status_label.value = f\"<b style='color: {color};'>{status}</b>\"\n",
    "    \n",
    "    def _update_timer(self, elapsed: float):\n",
    "        mins, secs = divmod(int(elapsed), 60)\n",
    "        self.timer_label.value = f\"<b>Time: {mins:02d}:{secs:02d}</b>\"\n",
    "    \n",
    "    def _update_results_counter(self):\n",
    "        self.results_counter.value = f\"<b>Results: {len(self.results)}</b>\"\n",
    "    \n",
    "    def _update_recording_indicator(self, is_recording: bool):\n",
    "        if is_recording:\n",
    "            self.recording_indicator.value = \"<span style='color: red;'>Recording...</span>\"\n",
    "        else:\n",
    "            self.recording_indicator.value = \"\"\n",
    "    \n",
    "    def _render_result(self, result: Dict) -> str:\n",
    "        \"\"\"Render a single result as HTML string.\"\"\"\n",
    "        label = result['classification']['predicted_label']\n",
    "        confidence = result['classification']['confidence']\n",
    "        text = result['text']\n",
    "        timestamp = result['timestamp']\n",
    "        \n",
    "        if label == 'hate':\n",
    "            bg_color = \"#ffdddd\"\n",
    "            label_color = \"red\"\n",
    "        else:\n",
    "            bg_color = \"#ddffdd\"\n",
    "            label_color = \"green\"\n",
    "        \n",
    "        probs = result['classification']['probabilities']\n",
    "        prob_str = \" | \".join([f\"{k}: {v:.1%}\" for k, v in probs.items()])\n",
    "        \n",
    "        return f\"\"\"\n",
    "        <div style='background: {bg_color}; padding: 8px; margin: 4px 0; border-radius: 6px; border-left: 3px solid {label_color};'>\n",
    "            <div style='color: #666; font-size: 11px;'>@{timestamp:.1f}s</div>\n",
    "            <div style='font-size: 14px; margin: 4px 0;'>{text}</div>\n",
    "            <div style='font-size: 12px;'>\n",
    "                <span style='color: {label_color}; font-weight: bold;'>{label.upper()}</span> ({confidence:.1%})\n",
    "                <span style='color: #888; font-size: 11px;'> - {prob_str}</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    def _update_results_display(self):\n",
    "        \"\"\"Update the results HTML widget with all results.\"\"\"\n",
    "        self.results_html.value = self._results_html\n",
    "    \n",
    "    def _add_message(self, msg: str, color: str = \"gray\"):\n",
    "        \"\"\"Add a status message to the results.\"\"\"\n",
    "        self._results_html += f\"<div style='color: {color}; margin: 4px 0;'>{msg}</div>\"\n",
    "        self._update_results_display()\n",
    "    \n",
    "    def _transcribe_audio(self, audio: np.ndarray) -> str:\n",
    "        \"\"\"Transcribe audio array to text using ChunkFormer.\"\"\"\n",
    "        temp_filename = None\n",
    "        try:\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
    "                temp_filename = f.name\n",
    "                with wave.open(temp_filename, 'wb') as wf:\n",
    "                    wf.setnchannels(self.config.CHANNELS)\n",
    "                    wf.setsampwidth(2)\n",
    "                    wf.setframerate(self.config.SAMPLE_RATE)\n",
    "                    audio_int16 = (audio * 32767).astype(np.int16)\n",
    "                    wf.writeframes(audio_int16.tobytes())\n",
    "            \n",
    "            text = asr_model.endless_decode(\n",
    "                audio_path=temp_filename,\n",
    "                chunk_size=64,\n",
    "                left_context_size=128,\n",
    "                right_context_size=128,\n",
    "                total_batch_duration=14400,\n",
    "                return_timestamps=False\n",
    "            )\n",
    "            return str(text).strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self._add_message(f\"Transcription error: {e}\", \"red\")\n",
    "            return \"\"\n",
    "        finally:\n",
    "            if temp_filename and os.path.exists(temp_filename):\n",
    "                os.remove(temp_filename)\n",
    "    \n",
    "    def _record_thread(self):\n",
    "        \"\"\"Background thread for audio recording.\"\"\"\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=self.config.CHANNELS,\n",
    "            rate=self.config.SAMPLE_RATE,\n",
    "            input=True,\n",
    "            input_device_index=self.config.INPUT_DEVICE_INDEX,\n",
    "            frames_per_buffer=self.config.CHUNK_SIZE\n",
    "        )\n",
    "        \n",
    "        threshold = self.calibrator.get_threshold()\n",
    "        \n",
    "        while self.recording:\n",
    "            if self.paused:\n",
    "                time.sleep(0.1)\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                data = stream.read(self.config.CHUNK_SIZE, exception_on_overflow=False)\n",
    "                audio_chunk = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "                \n",
    "                rms = np.sqrt(np.mean(audio_chunk ** 2))\n",
    "                \n",
    "                if rms > threshold:\n",
    "                    self.last_speech_time = time.time()\n",
    "                    if not self.speech_active:\n",
    "                        self.speech_active = True\n",
    "                        self._update_recording_indicator(True)\n",
    "                \n",
    "                if self.speech_active:\n",
    "                    with self.lock:\n",
    "                        self.audio_buffer = np.concatenate((self.audio_buffer, audio_chunk))\n",
    "                    \n",
    "                    if time.time() - self.last_speech_time > self.config.SILENCE_DURATION:\n",
    "                        self.speech_active = False\n",
    "                        self._update_recording_indicator(False)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                self._add_message(f\"Recording error: {e}\", \"red\")\n",
    "                break\n",
    "        \n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "    \n",
    "    def _process_thread(self):\n",
    "        \"\"\"Background thread for transcription and classification.\"\"\"\n",
    "        while self.recording:\n",
    "            if self.paused:\n",
    "                time.sleep(0.1)\n",
    "                continue\n",
    "                \n",
    "            # Update timer\n",
    "            if self._start_time:\n",
    "                elapsed = time.time() - self._start_time\n",
    "                self._update_timer(elapsed)\n",
    "            \n",
    "            with self.lock:\n",
    "                buffer_duration = len(self.audio_buffer) / self.config.SAMPLE_RATE\n",
    "            \n",
    "            should_process = False\n",
    "            \n",
    "            if buffer_duration >= self.config.MAX_RECORDING_DURATION:\n",
    "                should_process = True\n",
    "            elif not self.speech_active and buffer_duration > 0.5:\n",
    "                should_process = True\n",
    "            \n",
    "            if should_process:\n",
    "                with self.lock:\n",
    "                    audio_to_process = self.audio_buffer.copy()\n",
    "                    self.audio_buffer = np.array([], dtype=np.float32)\n",
    "                \n",
    "                if len(audio_to_process) > 0:\n",
    "                    self._update_status(\"Transcribing...\", \"blue\")\n",
    "                    \n",
    "                    transcribed_text = self._transcribe_audio(audio_to_process)\n",
    "                    \n",
    "                    if transcribed_text:\n",
    "                        self._update_status(\"Classifying...\", \"purple\")\n",
    "                        \n",
    "                        classification = classify_text(transcribed_text)\n",
    "                        \n",
    "                        elapsed = time.time() - self._start_time\n",
    "                        result = {\n",
    "                            \"timestamp\": elapsed,\n",
    "                            \"text\": transcribed_text,\n",
    "                            \"classification\": classification\n",
    "                        }\n",
    "                        self.results.append(result)\n",
    "                        \n",
    "                        # Add result to HTML and update display\n",
    "                        self._results_html += self._render_result(result)\n",
    "                        self._update_results_display()\n",
    "                        self._update_results_counter()\n",
    "                    \n",
    "                    self._update_status(\"Listening...\", \"green\")\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the widget UI.\"\"\"\n",
    "        display(self.main_widget)\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start recording.\"\"\"\n",
    "        if self.recording:\n",
    "            return\n",
    "            \n",
    "        self.recording = True\n",
    "        self.paused = False\n",
    "        self.results = []\n",
    "        self._results_html = \"\"\n",
    "        self._start_time = time.time()\n",
    "        self.audio_buffer = np.array([], dtype=np.float32)\n",
    "        \n",
    "        # Update UI\n",
    "        self._update_status(\"Listening...\", \"green\")\n",
    "        self.start_button.disabled = True\n",
    "        self.pause_button.disabled = False\n",
    "        self.stop_button.disabled = False\n",
    "        \n",
    "        # Start threads\n",
    "        self.record_thread = threading.Thread(target=self._record_thread, daemon=True)\n",
    "        self.process_thread = threading.Thread(target=self._process_thread, daemon=True)\n",
    "        self.record_thread.start()\n",
    "        self.process_thread.start()\n",
    "        \n",
    "        self._add_message(\"Recording started...\", \"green\")\n",
    "    \n",
    "    def pause(self):\n",
    "        \"\"\"Pause recording.\"\"\"\n",
    "        self.paused = True\n",
    "        self._update_status(\"Paused\", \"orange\")\n",
    "        self._update_recording_indicator(False)\n",
    "        self.pause_button.description = \"Resume\"\n",
    "        self.pause_button.button_style = \"success\"\n",
    "        self._add_message(\"Paused\", \"orange\")\n",
    "    \n",
    "    def resume(self):\n",
    "        \"\"\"Resume recording.\"\"\"\n",
    "        self.paused = False\n",
    "        self._update_status(\"Listening...\", \"green\")\n",
    "        self.pause_button.description = \"Pause\"\n",
    "        self.pause_button.button_style = \"warning\"\n",
    "        self._add_message(\"Resumed\", \"green\")\n",
    "    \n",
    "    def stop(self) -> List[Dict]:\n",
    "        \"\"\"Stop recording and return results.\"\"\"\n",
    "        self.recording = False\n",
    "        self._update_status(\"Stopped\", \"gray\")\n",
    "        self._update_recording_indicator(False)\n",
    "        \n",
    "        # Update UI\n",
    "        self.start_button.disabled = False\n",
    "        self.pause_button.disabled = True\n",
    "        self.pause_button.description = \"Pause\"\n",
    "        self.pause_button.button_style = \"warning\"\n",
    "        self.stop_button.disabled = True\n",
    "        \n",
    "        if hasattr(self, 'record_thread'):\n",
    "            self.record_thread.join(timeout=2.0)\n",
    "        if hasattr(self, 'process_thread'):\n",
    "            self.process_thread.join(timeout=2.0)\n",
    "        \n",
    "        hate_count = sum(1 for r in self.results if r['classification']['predicted_label'] == 'hate')\n",
    "        clean_count = len(self.results) - hate_count\n",
    "        self._results_html += f\"\"\"\n",
    "            <div style='background: #f0f0f0; padding: 8px; margin-top: 8px; border-radius: 6px;'>\n",
    "                <b>Session Complete</b> - Total: {len(self.results)} | Clean: {clean_count} | Hate: {hate_count}\n",
    "            </div>\n",
    "        \"\"\"\n",
    "        self._update_results_display()\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def get_results(self) -> List[Dict]:\n",
    "        \"\"\"Get all results.\"\"\"\n",
    "        return self.results.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac929d25",
   "metadata": {},
   "source": [
    "## 7. Initialize and Calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41bc3823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Audio Input Devices:\n",
      "  [0] Loopback: PCM (hw:0,0)\n",
      "  [1] Loopback: PCM (hw:0,1)\n",
      "  [6] sof-hda-dsp: - (hw:2,0)\n",
      "  [10] sof-hda-dsp: - (hw:2,6)\n",
      "  [11] sof-hda-dsp: - (hw:2,7)\n",
      "  [13] sysdefault\n",
      "  [15] surround21\n",
      "  [21] lavrate\n",
      "  [22] samplerate\n",
      "  [23] speexrate\n",
      "  [24] pipewire\n",
      "  [25] pulse\n",
      "  [26] speex\n",
      "  [27] upmix\n",
      "  [28] vdownmix\n",
      "  [30] default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM cards.pcm.side\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.iec958.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM iec958\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.iec958.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM spdif\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.iec958.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM spdif\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.hdmi.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM hdmi\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.hdmi.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM hdmi\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM cards.pcm.phoneline:CARD=0,DEV=0\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM cards.pcm.phoneline:CARD=0,DEV=0\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM phoneline\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM phoneline\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "ALSA lib pcm_oss.c:404:(_snd_pcm_oss_open) [error.] Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:404:(_snd_pcm_oss_open) [error.] Cannot open device /dev/dsp\n",
      "ALSA lib pcm_a52.c:1036:(_snd_pcm_a52_open) [error.] a52 is only for playback\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.iec958.0:CARD=0,AES0=6,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM iec958:{AES0 0x6 AES1 0x82 AES2 0x0 AES3 0x2 CARD 0}\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) [error.core] Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:481:(_snd_pcm_usb_stream_open) [error.] Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) [error.core] Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:481:(_snd_pcm_usb_stream_open) [error.] Invalid card 'card'\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    }
   ],
   "source": [
    "# Initialize calibrator\n",
    "calibrator = RobustNoiseCalibrator(config)\n",
    "\n",
    "# List available devices\n",
    "devices = calibrator.list_audio_devices()\n",
    "\n",
    "# Set device index if needed (uncomment and modify)\n",
    "# config.INPUT_DEVICE_INDEX = 0  # Change to your desired device index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0614981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM cards.pcm.side\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.iec958.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM iec958\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.iec958.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM spdif\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.iec958.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM spdif\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.hdmi.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM hdmi\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.hdmi.0:CARD=0,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM hdmi\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM cards.pcm.phoneline:CARD=0,DEV=0\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM cards.pcm.phoneline:CARD=0,DEV=0\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM phoneline\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.modem.0:CARD=0'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM phoneline\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "ALSA lib pcm_oss.c:404:(_snd_pcm_oss_open) [error.] Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:404:(_snd_pcm_oss_open) [error.] Cannot open device /dev/dsp\n",
      "ALSA lib pcm_a52.c:1036:(_snd_pcm_a52_open) [error.] a52 is only for playback\n",
      "ALSA lib confmisc.c:1377:(snd_func_refer) [error.core] Unable to find definition 'cards.0.pcm.iec958.0:CARD=0,AES0=6,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5207:(_snd_config_evaluate) [error.core] function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5730:(snd_config_expand) [error.core] Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) [error.pcm] Unknown PCM iec958:{AES0 0x6 AES1 0x82 AES2 0x0 AES3 0x2 CARD 0}\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) [error.core] Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:481:(_snd_pcm_usb_stream_open) [error.] Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) [error.core] Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:481:(_snd_pcm_usb_stream_open) [error.] Invalid card 'card'\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Calibration - Stay silent for 3.0s...\n",
      "  Progress: 100%\n",
      "Calibration complete [OK]\n",
      "  Noise RMS: 0.13669, Threshold: 0.10000\n"
     ]
    }
   ],
   "source": [
    "# Perform noise calibration\n",
    "noise_stats = calibrator.calibrate(show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df3b194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Recalibrate if the environment changes\n",
    "# noise_stats = calibrator.calibrate(show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e157f0",
   "metadata": {},
   "source": [
    "## 8. Run Real-time ASR + Classification\n",
    "\n",
    "Run the cell below to display the interactive widget with:\n",
    "- **▶️ Start** - Begin continuous recording\n",
    "- **⏸️ Pause / ▶️ Resume** - Temporarily pause/resume recording  \n",
    "- **⏹️ Stop** - Stop and show session summary\n",
    "- **🗑️ Clear** - Clear all results\n",
    "\n",
    "The system will automatically:\n",
    "1. Detect when you start/stop speaking\n",
    "2. Transcribe speech segments (max 30s each)\n",
    "3. Classify each segment and display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b43237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbb826936af4b1085e9521ad9bf42b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Real-time ASR + Classification</h3>'), HBox(children=(HTML(value=\"<b style='col…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the pipeline with widget UI\n",
    "pipeline = RealtimeASRClassifierWidget(config, calibrator)\n",
    "\n",
    "# Display the interactive widget\n",
    "# Use the Start/Pause/Stop buttons to control recording\n",
    "# Results will appear in the scrollable area below\n",
    "pipeline.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa55e09",
   "metadata": {},
   "source": [
    "## 10. Test Classification on Custom Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c5dbf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Text Classification\n",
      "--------------------------------------------------\n",
      "Text: Xin chào, hôm nay trời đẹp quá\n",
      "  -> clean (100.0%)\n",
      "\n",
      "Text: Cảm ơn bạn rất nhiều\n",
      "  -> clean (100.0%)\n",
      "\n",
      "Text: Tôi rất vui được gặp bạn\n",
      "  -> clean (100.0%)\n",
      "\n",
      "Text: Mày ngu\n",
      "  -> hate (99.9%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the classifier on sample texts\n",
    "test_texts = [\n",
    "    \"Xin chào, hôm nay trời đẹp quá\",\n",
    "    \"Cảm ơn bạn rất nhiều\",\n",
    "    \"Tôi rất vui được gặp bạn\",\n",
    "    \"Mày ngu\"\n",
    "]\n",
    "\n",
    "print(\"Testing Text Classification\")\n",
    "print(\"-\" * 50)\n",
    "for text in test_texts:\n",
    "    result = classify_text(text)\n",
    "    label = result['predicted_label']\n",
    "    confidence = result['confidence']\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"  -> {label} ({confidence:.1%})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5888adbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907798da32d24604afd2566625227e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Text:', layout=Layout(width='80%'), placeholder='Enter Vietnamese t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive text classification\n",
    "def classify_interactive(text):\n",
    "    if text.strip():\n",
    "        result = classify_text(text)\n",
    "        label = result['predicted_label']\n",
    "        confidence = result['confidence']\n",
    "        probs = result['probabilities']\n",
    "        \n",
    "        print(f\"{label.upper()} ({confidence:.1%})\")\n",
    "        print(f\"Probs: {' | '.join([f'{k}: {v:.1%}' for k, v in probs.items()])}\")\n",
    "\n",
    "text_input = widgets.Text(\n",
    "    placeholder='Enter Vietnamese text to classify...',\n",
    "    description='Text:',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "classify_button = widgets.Button(description='Classify', button_style='primary')\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        classify_interactive(text_input.value)\n",
    "\n",
    "classify_button.on_click(on_button_click)\n",
    "display(widgets.VBox([text_input, classify_button, output]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai002",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
